<!DOCTYPE html>
<html lang="zh-Hans">
<head>

    <!--[if lt IE 9]>
        <style>body {display: none; background: none !important} </style>
        <meta http-equiv="Refresh" Content="0; url=//outdatedbrowser.com/" />
    <![endif]-->

<meta charset="utf-8">
<meta http-equiv="X-UA-Compatible" content="IE=edge, chrome=1" />
<meta name="viewport" content="width=device-width, initial-scale=1, maximum-scale=1, user-scalable=no">
<meta name="format-detection" content="telephone=no" />
<meta name="author" content="wyq" />



<meta name="description" content="什么是 Attention ？我们来一起看着下面这张图片，并且读一下下面这句话。  一只黄色的小猫带着一个鹿角帽子趴在沙发上。   在读这句话的过程中，你的注意力是不是会发生变化？我相信大多数人是这样的：当读到“小猫”的时候，注意力在猫身上；当读到“鹿角帽子”的时候，注意力在鹿角帽子上。 这就是人类的注意力，它是会随着时间发生变化的。">
<meta property="og:type" content="article">
<meta property="og:title" content="Attention——深度学习中的注意力机制">
<meta property="og:url" content="http://hf136.github.io/2019/01/27/attention/index.html">
<meta property="og:site_name" content="wyq&#39;s blog">
<meta property="og:description" content="什么是 Attention ？我们来一起看着下面这张图片，并且读一下下面这句话。  一只黄色的小猫带着一个鹿角帽子趴在沙发上。   在读这句话的过程中，你的注意力是不是会发生变化？我相信大多数人是这样的：当读到“小猫”的时候，注意力在猫身上；当读到“鹿角帽子”的时候，注意力在鹿角帽子上。 这就是人类的注意力，它是会随着时间发生变化的。">
<meta property="og:locale" content="zh-Hans">
<meta property="og:image" content="http://hf136.github.io/resource/images/cat.png">
<meta property="og:image" content="http://hf136.github.io/resource/images/seq2seq.png">
<meta property="og:image" content="http://hf136.github.io/resource/images/attention-1.png">
<meta property="og:updated_time" content="2019-01-27T10:15:21.026Z">
<meta name="twitter:card" content="summary">
<meta name="twitter:title" content="Attention——深度学习中的注意力机制">
<meta name="twitter:description" content="什么是 Attention ？我们来一起看着下面这张图片，并且读一下下面这句话。  一只黄色的小猫带着一个鹿角帽子趴在沙发上。   在读这句话的过程中，你的注意力是不是会发生变化？我相信大多数人是这样的：当读到“小猫”的时候，注意力在猫身上；当读到“鹿角帽子”的时候，注意力在鹿角帽子上。 这就是人类的注意力，它是会随着时间发生变化的。">
<meta name="twitter:image" content="http://hf136.github.io/resource/images/cat.png">

<link rel="apple-touch-icon" href= "/apple-touch-icon.png">


    <link rel="alternate" href="/atom.xml" title="wyq&#39;s blog" type="application/atom+xml">



    <link rel="shortcut icon" href="/img/avatar.jpg">





    <link href="//cdn.bootcss.com/fancybox/2.1.5/jquery.fancybox.min.css" rel="stylesheet">



    <script src="//cdn.bootcss.com/pace/1.0.2/pace.min.js"></script>
    <link href="//cdn.bootcss.com/pace/1.0.2/themes/blue/pace-theme-minimal.css" rel="stylesheet">


<link rel="stylesheet" href="/css/style.css">



<link href="//cdn.bootcss.com/font-awesome/4.6.3/css/font-awesome.min.css" rel="stylesheet">


<title>Attention——深度学习中的注意力机制 | wyq&#39;s blog</title>

<script src="//cdn.bootcss.com/jquery/2.2.4/jquery.min.js"></script>
<script src="//cdn.bootcss.com/clipboard.js/1.5.10/clipboard.min.js"></script>

<script>
    var yiliaConfig = {
        fancybox: true,
        animate: false,
        isHome: false,
        isPost: true,
        isArchive: false,
        isTag: false,
        isCategory: false,
        fancybox_js: "//cdn.bootcss.com/fancybox/2.1.5/jquery.fancybox.min.js",
        scrollreveal: "//cdn.bootcss.com/scrollReveal.js/3.1.4/scrollreveal.min.js",
        search: true
    }
</script>


    <script> yiliaConfig.jquery_ui = [false]; </script>



    <script> yiliaConfig.rootUrl = "\/";</script>






</head>
<body>
  <div id="container">
    <div class="left-col">
    <div class="overlay"></div>
<div class="intrude-less">
    <header id="header" class="inner">
        <a href="/" class="profilepic">
            <img src="/img/avatar.jpg" class="animated zoomIn">
        </a>
        <hgroup>
          <h1 class="header-author"><a href="/">wyq</a></h1>
        </hgroup>

        
        <p class="header-subtitle">纸上得来终觉浅，绝知此事要躬行</p>
        

        
            <form id="search-form">
            <input type="text" id="local-search-input" name="q" placeholder="search..." class="search form-control" autocomplete="off" autocorrect="off" searchonload="false" />
            <i class="fa fa-times" onclick="resetSearch()"></i>
            </form>
            <div id="local-search-result"></div>
            <p class='no-result'>No results found <i class='fa fa-spinner fa-pulse'></i></p>
        


        
            <div id="switch-btn" class="switch-btn">
                <div class="icon">
                    <div class="icon-ctn">
                        <div class="icon-wrap icon-house" data-idx="0">
                            <div class="birdhouse"></div>
                            <div class="birdhouse_holes"></div>
                        </div>
                        <div class="icon-wrap icon-ribbon hide" data-idx="1">
                            <div class="ribbon"></div>
                        </div>
                        
                        
                        <div class="icon-wrap icon-me hide" data-idx="3">
                            <div class="user"></div>
                            <div class="shoulder"></div>
                        </div>
                        
                    </div>
                    
                </div>
                <div class="tips-box hide">
                    <div class="tips-arrow"></div>
                    <ul class="tips-inner">
                        <li>菜单</li>
                        <li>标签</li>
                        
                        
                        <li>关于我</li>
                        
                    </ul>
                </div>
            </div>
        

        <div id="switch-area" class="switch-area">
            <div class="switch-wrap">
                <section class="switch-part switch-part1">
                    <nav class="header-menu">
                        <ul>
                        
                            <li><a href="/">主页</a></li>
                        
                            <li><a href="/archives/">所有文章</a></li>
                        
                            <li><a href="/about/">关于我</a></li>
                        
                        </ul>
                    </nav>
                    <nav class="header-nav">
                        <ul class="social">
                            
                                <a class="fa Email" href="mailto:wuyueqiu666@foxmail.com" title="Email"></a>
                            
                                <a class="fa GitHub" href="https://github.com/hf136" title="GitHub"></a>
                            
                                <a class="fa RSS" href="/atom.xml" title="RSS"></a>
                            
                        </ul>
                    </nav>
                </section>
                
                
                <section class="switch-part switch-part2">
                    <div class="widget tagcloud" id="js-tagcloud">
                        <ul class="tag-list"><li class="tag-list-item"><a class="tag-list-link" href="/tags/Deep-Learning/">Deep Learning</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/Machine-Learning/">Machine Learning</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/Math/">Math</a></li></ul>
                    </div>
                </section>
                
                
                

                
                
                <section class="switch-part switch-part3">
                
                    <div id="js-aboutme">一切皆有可能</div>
                </section>
                
            </div>
        </div>
    </header>                
</div>
    </div>
    <div class="mid-col">
      <nav id="mobile-nav">
      <div class="overlay">
          <div class="slider-trigger"></div>
          <h1 class="header-author js-mobile-header hide"><a href="/" title="回到主页">wyq</a></h1>
      </div>
    <div class="intrude-less">
        <header id="header" class="inner">
            <a href="/" class="profilepic">
                <img src="/img/avatar.jpg" class="animated zoomIn">
            </a>
            <hgroup>
              <h1 class="header-author"><a href="/" title="回到主页">wyq</a></h1>
            </hgroup>
            
            <p class="header-subtitle">纸上得来终觉浅，绝知此事要躬行</p>
            
            <nav class="header-menu">
                <ul>
                
                    <li><a href="/">主页</a></li>
                
                    <li><a href="/archives/">所有文章</a></li>
                
                    <li><a href="/about/">关于我</a></li>
                
                <div class="clearfix"></div>
                </ul>
            </nav>
            <nav class="header-nav">
                        <ul class="social">
                            
                                <a class="fa Email" target="_blank" href="mailto:wuyueqiu666@foxmail.com" title="Email"></a>
                            
                                <a class="fa GitHub" target="_blank" href="https://github.com/hf136" title="GitHub"></a>
                            
                                <a class="fa RSS" target="_blank" href="/atom.xml" title="RSS"></a>
                            
                        </ul>
            </nav>
        </header>                
    </div>
    <link class="menu-list" tags="标签" friends="友情链接" about="关于我"/>
</nav>
      <div class="body-wrap"><article id="post-attention" class="article article-type-post" itemscope itemprop="blogPost">
  
    <div class="article-meta">
      <a href="/2019/01/27/attention/" class="article-date">
      <time datetime="2019-01-27T03:24:28.000Z" itemprop="datePublished">2019-01-27</time>
</a>


    </div>
  
  <div class="article-inner">
    
      <input type="hidden" class="isFancy" />
    
    
      <header class="article-header">
        
  
    <h1 class="article-title" itemprop="name">
      Attention——深度学习中的注意力机制
    </h1>
  

      </header>
      
      <div class="article-info article-info-post">
        

        
        <div class="clearfix"></div>
      </div>
      
    
    <div class="article-entry" itemprop="articleBody">
      
          
        <h2 id="什么是-Attention-？"><a href="#什么是-Attention-？" class="headerlink" title="什么是 Attention ？"></a>什么是 Attention ？</h2><p>我们来一起看着下面这张图片，并且读一下下面这句话。</p>
<blockquote>
<p>一只黄色的小猫带着一个鹿角帽子趴在沙发上。</p>
</blockquote>
<p><img src="/resource/images/cat.png" alt="cat"></p>
<p>在读这句话的过程中，你的注意力是不是会发生变化？我相信大多数人是这样的：当读到“小猫”的时候，注意力在猫身上；当读到“鹿角帽子”的时候，注意力在鹿角帽子上。</p>
<p>这就是人类的注意力，它是会随着时间发生变化的。</p>
<a id="more"></a>
<h2 id="神经网络中的-Attention-机制"><a href="#神经网络中的-Attention-机制" class="headerlink" title="神经网络中的 Attention 机制"></a>神经网络中的 Attention 机制</h2><h3 id="seq2seq-模型"><a href="#seq2seq-模型" class="headerlink" title="seq2seq 模型"></a>seq2seq 模型</h3><p><img src="/resource/images/seq2seq.png" alt="seq2seq"></p>
<p>seq2seq 是指 sequence to sequence，这类模型的输入是一个序列 x1、x2、x3 …，输出也是一个序列 y1、y2 …。它通常由两个类似于 LSTM 的循环神经网络（RNN）构成，也常被称作 Encoder-Decoder 模型，第一个 RNN 进行 encode，第二个 RNN 作为 decode。</p>
<p>一般的 Encoder-Decoder 模型，Encoder阶段可以表示为：</p>
<p>$$<br>\begin{aligned}<br>    h_t =&amp; f(x_t, h_{t-1}) \\<br>    c   =&amp; q(h_1, … ,h_T) \\<br>\end{aligned}<br>$$</p>
<p>其中： $h_t$ 是 n 维实数向量，表示编码阶段RNN的 t 时刻的隐藏状态；c 是各个时刻隐藏状态生成的向量；𝑓 和 𝑞 是非线性函数。例如：$f$ 可以是 LSTM，$q$ 函数取最后一个时刻的输出结果，$q({h_1, … ,h_{T_x}}) = h_T$ 。</p>
<p>Decoder 阶段可以表示为：</p>
<p>$$<br>\begin{aligned}<br>    y_t =&amp; g(y_{t-1}, s_t, c) \\<br>\end{aligned}<br>$$</p>
<p>其中， $y_t$ 是 t 时刻的输出结果，初始化 $y_0$ 为零向量，$s_t$ 为 t 时刻隐藏层状态，c 为 Encoder 阶段的输出结果；g 是非线性函数。例如：g 是一个 LSTM 单元，把 $y_{t-1}， c$ 拼起来当做输入。</p>
<p>在机器翻译、对话生成等场景中经常会用到这类模型，但这类模型是有一些局限性的。</p>
<ul>
<li>局限性：编码和解码之间的唯一联系就是一个固定长度的语义向量 C ；在输入序列较长的情况下信息损失更加严重。</li>
</ul>
<h3 id="Attention-模型原理"><a href="#Attention-模型原理" class="headerlink" title="Attention 模型原理"></a>Attention 模型原理</h3><p>由于单纯的seq2seq会存在一些问题，于是人类便发明在神经网络加入模拟人类注意力的机制。</p>
<p>下面我们为上面的 Encoder-Decoder 模型加入一种 Attention 机制。</p>
<p>Attention 机制改变的是 Encoder-Decoder 模型中的 Decoder 阶段；Encoder 阶段不变，将 Decoder 阶段变成：</p>
<p>$$<br>\begin{aligned}<br>    y_t =&amp; g(y_{t-1}, s_t, c_t)<br>\end{aligned}<br>$$</p>
<p>单一向量 c 变成了一组向量 $c_t$ ，它的计算方式为：</p>
<p>$$<br>c_t = \sum_j^T{\alpha_{tj} h_j}<br>$$</p>
<p>其中， $h_j \in {(h_1, … ,h_T)}$ ，即 $h_j$ 为Encoder阶段j时刻的输出，$\alpha_{tj}$ 为t时刻第j个隐藏层的权重系数，它可以通过一个前馈神经网络学习得到：</p>
<p>$$<br>\begin{aligned}<br>    c_{tj} = \frac{\rm{exp}(e_{tj})} {\sum_{k=1}^T{ \rm{exp}(e_{tk}) }} \\<br>    e_{tj} = a(s_{t-1}, h_j)<br>\end{aligned}<br>$$</p>
<p>其中，𝑎 是一个前馈神经网络，比如：𝑎 可以是一个由 tanh 作为激活函数的神经元。$s_{t-1}$ 为t-1时刻的decoder阶段的隐藏层状态，$h_j$ encoder 阶段 j 时刻的输出。</p>
<p>总的来说就是：</p>
<blockquote>
<p>t 时刻的向量 $c_t$ 是由encoder阶段各个时刻的输出 $h_t$ 加权得到的结果；<br>而这个加权的权重是由decoder阶段t-1时刻的隐藏层状态 $s_{t-1}$ 和encoder阶段各个时刻的输出 $h_t$ 通过一个前馈神经网络并归一化之后的结果。</p>
</blockquote>
<h3 id="Attention-机制可视化"><a href="#Attention-机制可视化" class="headerlink" title="Attention 机制可视化"></a>Attention 机制可视化</h3><p><img src="/resource/images/attention-1.png" alt="attention model"></p>
<p>图中，横轴为：输入的英文单词序列，纵轴为：输出的法语单词序列；每一行是权值 𝛼 组成的向量；越亮的地方权重越大。</p>
<p>这相当于实现了一种 “软对齐” 机制，所以注意力机制有时也叫做 “对齐模型” （Alignment Model）。</p>
<h2 id="参考资料"><a href="#参考资料" class="headerlink" title="参考资料"></a>参考资料</h2><p><a href="https://arxiv.org/abs/1409.0473" target="_blank" rel="noopener">https://arxiv.org/abs/1409.0473</a><br><a href="https://mp.weixin.qq.com/s/_Ru6GMcrSO25bTs8vM6FmA" target="_blank" rel="noopener">https://mp.weixin.qq.com/s/_Ru6GMcrSO25bTs8vM6FmA</a></p>

      
    </div>
    
  </div>
  
    
    <div class="copyright">
        <p><span>本文标题:</span><a href="/2019/01/27/attention/">Attention——深度学习中的注意力机制</a></p>
        <p><span>文章作者:</span><a href="/" title="回到主页">wyq</a></p>
        <p><span>发布时间:</span>2019-01-27, 11:24:28</p>
        <p><span>最后更新:</span>2019-01-27, 18:15:21</p>
        <p>
            <span>原始链接:</span><a class="post-url" href="/2019/01/27/attention/" title="Attention——深度学习中的注意力机制">http://hf136.github.io/2019/01/27/attention/</a>
            <span class="copy-path" data-clipboard-text="原文: http://hf136.github.io/2019/01/27/attention/　　作者: wyq" title="点击复制文章链接"><i class="fa fa-clipboard"></i></span>
            <script> var clipboard = new Clipboard('.copy-path'); </script>
        </p>
        <p>
            <span>许可协议:</span><i class="fa fa-creative-commons"></i> <a rel="license" href="http://creativecommons.org/licenses/by-nc-sa/4.0/" title="CC BY-NC-SA 4.0 International" target = "_blank">"署名-非商用-相同方式共享 4.0"</a> 转载请保留原文链接及作者。
        </p>
    </div>



    <nav id="article-nav">
        
        
            <div id="article-nav-older" class="article-nav-title">
                <a href="/2019/01/19/LSTM/">
                    LSTM
                </a>
            </div>
        
    </nav>

  
</article>

    <div id="toc" class="toc-article">
        <strong class="toc-title">文章目录</strong>
        
            <ol class="toc"><li class="toc-item toc-level-2"><a class="toc-link" href="#什么是-Attention-？"><span class="toc-number">1.</span> <span class="toc-text">什么是 Attention ？</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#神经网络中的-Attention-机制"><span class="toc-number">2.</span> <span class="toc-text">神经网络中的 Attention 机制</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#seq2seq-模型"><span class="toc-number">2.1.</span> <span class="toc-text">seq2seq 模型</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#Attention-模型原理"><span class="toc-number">2.2.</span> <span class="toc-text">Attention 模型原理</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#Attention-机制可视化"><span class="toc-number">2.3.</span> <span class="toc-text">Attention 机制可视化</span></a></li></ol></li><li class="toc-item toc-level-2"><a class="toc-link" href="#参考资料"><span class="toc-number">3.</span> <span class="toc-text">参考资料</span></a></li></ol>
        
    </div>
    <style>
        .left-col .switch-btn,
        .left-col .switch-area {
            display: none;
        }
        .toc-level-3 i,
        .toc-level-3 ol {
            display: none !important;
        }
    </style>

    <input type="button" id="tocButton" value="隐藏目录"  title="点击按钮隐藏或者显示文章目录">

    <script>
        yiliaConfig.toc = ["隐藏目录", "显示目录", !!"false"];
    </script>



    
<div class="share">
    

    
</div>







    




    <div class="scroll" id="post-nav-button">
        
            <a href="/" title="回到主页"><i class="fa fa-home"></i></a>
        

        <a title="文章列表"><i class="fa fa-bars"></i><i class="fa fa-times"></i></a>

        
            <a href="/2019/01/19/LSTM/" title="下一篇: LSTM">
                <i class="fa fa-angle-right"></i>
            </a>
        
    </div>

    <ul class="post-list"><li class="post-list-item"><a class="post-list-link" href="/2019/01/27/attention/">Attention——深度学习中的注意力机制</a></li><li class="post-list-item"><a class="post-list-link" href="/2019/01/19/LSTM/">LSTM</a></li><li class="post-list-item"><a class="post-list-link" href="/2018/12/28/rnn/">循环神经网络（Recurrent Neural Network）</a></li><li class="post-list-item"><a class="post-list-link" href="/2018/11/18/neural-network/">人工神经网络（Artificial Neural Network）</a></li><li class="post-list-item"><a class="post-list-link" href="/2018/11/17/regularization/">正则化（regularization）</a></li><li class="post-list-item"><a class="post-list-link" href="/2018/11/03/logistic-regression/">逻辑回归（Logistic Regression）</a></li><li class="post-list-item"><a class="post-list-link" href="/2018/09/27/linear-regression/">线性回归（Linear Regression）</a></li><li class="post-list-item"><a class="post-list-link" href="/2018/09/20/math/">函数的导数</a></li><li class="post-list-item"><a class="post-list-link" href="/2018/09/19/EasyML-1/">机器学习入门——什么是机器学习？</a></li></ul>




    <script>
        
    </script>
</div>
      <footer id="footer">
    <div class="outer">
        <div id="footer-info">
            <div class="footer-left">
                <i class="fa fa-copyright"></i> 
                2018-2019 wyq
            </div>
            <div class="footer-right">
                <a href="http://hexo.io/" target="_blank" title="快速、简洁且高效的博客框架">Hexo</a>  Theme <a href="https://github.com/MOxFIVE/hexo-theme-yelee" target="_blank" title="简而不减 Hexo 双栏博客主题  v3.5">Yelee</a></i>
            </div>
        </div>
        
            <div class="visit">
                
                    <span id="busuanzi_container_site_pv" style='display:none'>
                        <span id="site-visit" title="本站到访数"><i class="fa fa-user" aria-hidden="true"></i><span id="busuanzi_value_site_uv"></span>
                        </span>
                    </span>
                
                
                    <span>| </span>
                
                
                    <span id="busuanzi_container_page_pv" style='display:none'>
                        <span id="page-visit"  title="本页阅读量"><i class="fa fa-eye animated infinite pulse" aria-hidden="true"></i><span id="busuanzi_value_page_pv"></span>
                        </span>
                    </span>
                
            </div>
        
    </div>
</footer>
    </div>
    
<script data-main="/js/main.js" src="//cdn.bootcss.com/require.js/2.2.0/require.min.js"></script>





    <script type="text/x-mathjax-config">
MathJax.Hub.Config({
    tex2jax: {
        inlineMath: [ ['$','$'], ["\\(","\\)"]  ],
        processEscapes: true,
        skipTags: ['script', 'noscript', 'style', 'textarea', 'pre', 'code']
    }
});

MathJax.Hub.Queue(function() {
    var all = MathJax.Hub.getAllJax(), i;
    for(i=0; i < all.length; i += 1) {
        all[i].SourceElement().parentNode.className += ' has-jax';                 
    }       
});
</script>

<script src="//cdn.bootcss.com/mathjax/2.6.1/MathJax.js?config=TeX-AMS-MML_HTMLorMML">
</script>


<div class="scroll" id="scroll">
    <a href="#" title="返回顶部"><i class="fa fa-arrow-up"></i></a>
    <a href="#comments" onclick="load$hide();" title="查看评论"><i class="fa fa-comments-o"></i></a>
    <a href="#footer" title="转到底部"><i class="fa fa-arrow-down"></i></a>
</div>
<script>
    // Open in New Window
    
        var oOpenInNew = {
            
            
            
            
            
            
             archives: ".archive-article-title", 
             miniArchives: "a.post-list-link", 
            
             friends: "#js-friends a", 
             socail: ".social a" 
        }
        for (var x in oOpenInNew) {
            $(oOpenInNew[x]).attr("target", "_blank");
        }
    
</script>

<script async src="https://dn-lbstatics.qbox.me/busuanzi/2.3/busuanzi.pure.mini.js">
</script>
  </div>
</body>
</html>